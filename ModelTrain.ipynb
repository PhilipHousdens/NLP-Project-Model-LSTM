{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Data",
   "id": "8f62f2d9b4e4b42d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-28T05:17:25.647037Z",
     "start_time": "2025-02-28T05:17:23.386683Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import random\n",
    "\n",
    "# Check CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preprocessing Function (using GPU where applicable)\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    return text\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T05:17:59.758152Z",
     "start_time": "2025-02-28T05:17:27.302592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Load and preprocess datasets\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['article'] = df['article'].apply(preprocess_text)\n",
    "    df['highlights'] = df['highlights'].apply(preprocess_text)\n",
    "    return df['article'].tolist(), df['highlights'].tolist()\n",
    "\n",
    "train_texts, train_summaries = load_data(\"resources/train.csv\")\n",
    "val_texts, val_summaries = load_data(\"resources/validation.csv\")\n",
    "\n",
    "SAMPLE_SIZE = 15000  # Adjust based on available GPU memory\n",
    "\n",
    "# Ensure we don't sample more than available data\n",
    "train_sample_size = min(SAMPLE_SIZE, len(train_texts))\n",
    "val_sample_size = min(SAMPLE_SIZE // 4, len(val_texts))  # Use smaller validation set\n",
    "\n",
    "# Randomly sample data\n",
    "train_sample_indices = random.sample(range(len(train_texts)), train_sample_size)\n",
    "val_sample_indices = random.sample(range(len(val_texts)), val_sample_size)\n",
    "\n",
    "# Subset the dataset\n",
    "train_texts = [train_texts[i] for i in train_sample_indices]\n",
    "train_summaries = [train_summaries[i] for i in train_sample_indices]\n",
    "\n",
    "val_texts = [val_texts[i] for i in val_sample_indices]\n",
    "val_summaries = [val_summaries[i] for i in val_sample_indices]\n"
   ],
   "id": "b3c9afa29adc41be",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Build vocabulary",
   "id": "67938b9a207b4b13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T05:18:55.614718Z",
     "start_time": "2025-02-28T05:18:54.043689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Flatten lists into a single Counter object\n",
    "word_counts = Counter(word for text in train_texts + train_summaries for word in text.split())\n",
    "\n",
    "# Build vocabulary\n",
    "vocab = {word: i+2 for i, (word, _) in enumerate(word_counts.items())}\n",
    "vocab[\"<PAD>\"] = 0\n",
    "vocab[\"<UNK>\"] = 1\n",
    "VOCAB_SIZE = len(vocab)\n"
   ],
   "id": "60947aaf6cf4cb0c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset Class",
   "id": "dee92db5aa04c037"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T05:18:55.625134Z",
     "start_time": "2025-02-28T05:18:55.619468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, summaries, vocab, max_len=100):\n",
    "        self.texts = [torch.tensor([vocab.get(word, 1) for word in text.split()], dtype=torch.long) for text in texts]\n",
    "        self.summaries = [torch.tensor([vocab.get(word, 1) for word in summary.split()], dtype=torch.long) for summary in summaries]\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx][:self.max_len]\n",
    "        summary = self.summaries[idx][:self.max_len]\n",
    "        return text, summary"
   ],
   "id": "281313773b68967c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Collate Function for Padding",
   "id": "e6cdc0247f60e74c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T05:18:58.462563Z",
     "start_time": "2025-02-28T05:18:58.458100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MAX_LEN = 128  # Set a reasonable sequence length\n",
    "\n",
    "def collate_fn(batch):\n",
    "    text, summary = zip(*batch)  # Unpack batch\n",
    "    \n",
    "    text = [torch.as_tensor(t[:MAX_LEN], dtype=torch.long).clone().detach() for t in text]\n",
    "    summary = [torch.as_tensor(s[:MAX_LEN], dtype=torch.long).clone().detach() for s in summary]\n",
    "\n",
    "    text = pad_sequence(text, batch_first=True, padding_value=0)  # Pad sequences\n",
    "    summary = pad_sequence(summary, batch_first=True, padding_value=0)\n",
    "\n",
    "    return text, summary\n",
    "\n"
   ],
   "id": "8e86937561c703a9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define LSTM Model",
   "id": "34c9484f74d5a31e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T05:18:59.965601Z",
     "start_time": "2025-02-28T05:18:59.960105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTMSeq2Seq(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super(LSTMSeq2Seq, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.encoder = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "        self.decoder = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        embed_src = self.embedding(src)\n",
    "        embed_tgt = self.embedding(tgt)\n",
    "        _, (hidden, cell) = self.encoder(embed_src)\n",
    "        output, _ = self.decoder(embed_tgt, (hidden, cell))\n",
    "        output = self.fc(output)\n",
    "        return output"
   ],
   "id": "950a8877130b8868",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##  Function to generate summary",
   "id": "5dbd797747bb13c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T05:19:01.299333Z",
     "start_time": "2025-02-28T05:19:01.294636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_summary(model, text, vocab, max_len=50):\n",
    "    model.eval()\n",
    "    text_tensor = torch.tensor([vocab.get(word, 1) for word in text.split()], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(text_tensor, text_tensor)\n",
    "    summary_indices = torch.argmax(output, dim=-1).squeeze(0).tolist()\n",
    "    summary = \" \".join([list(vocab.keys())[list(vocab.values()).index(idx)] for idx in summary_indices if idx in vocab.values()])\n",
    "    return summary"
   ],
   "id": "1cd008bc039281b1",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T05:19:02.641939Z",
     "start_time": "2025-02-28T05:19:02.638592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EMBED_SIZE = 64\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "LR = 0.001"
   ],
   "id": "5251780891645be5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create DataLoaders",
   "id": "3b9a910a659cb04a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T05:19:06.830433Z",
     "start_time": "2025-02-28T05:19:03.988778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "# Define subset size (e.g., 50,000 samples)\n",
    "subset_size = 10000  \n",
    "train_indices = list(range(min(subset_size, len(train_texts))))\n",
    "val_indices = list(range(min(subset_size, len(val_texts))))\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_dataset = NewsDataset(train_texts, train_summaries, vocab)\n",
    "val_dataset = NewsDataset(val_texts, val_summaries, vocab)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collate_fn, pin_memory=True\n",
    ")\n",
    "\n",
    "\n"
   ],
   "id": "98c8636225b02a05",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T05:19:08.267330Z",
     "start_time": "2025-02-28T05:19:06.835387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = LSTMSeq2Seq(VOCAB_SIZE, EMBED_SIZE, HIDDEN_SIZE).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ],
   "id": "56fafcb0f69fdc64",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training loop",
   "id": "eabb3c885f4ed266"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T05:19:09.220459Z",
     "start_time": "2025-02-28T05:19:08.299040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()  \n",
    "torch.cuda.empty_cache()\n",
    "model = torch.compile(model)  # JIT Compilation for speedup\n",
    "\n"
   ],
   "id": "efd9178b2dffd881",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T05:19:09.254818Z",
     "start_time": "2025-02-28T05:19:09.248260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.amp import autocast, GradScaler  # Ensure correct import\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    ACCUMULATION_STEPS = 2\n",
    "    scaler = GradScaler()  # ✅ No need for `device=\"cuda\"`\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        for i, (text, summary) in enumerate(train_loader):\n",
    "            text = text.to(device, non_blocking=True)  \n",
    "            summary = summary.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.autocast(\"cuda\", dtype=torch.float16):  # ✅ Fixed!\n",
    "                output = model(text, summary[:, :-1])\n",
    "                loss = criterion(output.view(-1, VOCAB_SIZE), summary[:, 1:].reshape(-1))\n",
    "\n",
    "            scaler.scale(loss).backward()  # ✅ Ensure AMP scaling\n",
    "        \n",
    "            if (i + 1) % ACCUMULATION_STEPS == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "    \n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for text, summary in val_loader:\n",
    "                text = text.to(device, non_blocking=True)\n",
    "                summary = summary.to(device, non_blocking=True)\n",
    "        \n",
    "                with autocast(device_type=\"cuda\", dtype=torch.float16):  # ✅ Fixed!\n",
    "                    output = model(text, summary[:, :-1])\n",
    "                    loss = criterion(output.view(-1, VOCAB_SIZE), summary[:, 1:].reshape(-1))\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")\n"
   ],
   "id": "92b9bf81de1f8131",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T05:30:01.707162Z",
     "start_time": "2025-02-28T05:19:09.722091Z"
    }
   },
   "cell_type": "code",
   "source": "train_model(model, train_loader, val_loader, criterion, optimizer, EPOCHS)",
   "id": "56b00891c923729f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 8.3354, Val Loss: 7.8288\n",
      "Epoch 2, Train Loss: 7.6266, Val Loss: 7.6198\n",
      "Epoch 3, Train Loss: 7.3651, Val Loss: 7.4777\n",
      "Epoch 4, Train Loss: 7.1631, Val Loss: 7.3809\n",
      "Epoch 5, Train Loss: 6.9952, Val Loss: 7.3168\n",
      "Epoch 6, Train Loss: 6.8389, Val Loss: 7.2571\n",
      "Epoch 7, Train Loss: 6.6927, Val Loss: 7.2142\n",
      "Epoch 8, Train Loss: 6.5580, Val Loss: 7.1885\n",
      "Epoch 9, Train Loss: 6.4293, Val Loss: 7.1717\n",
      "Epoch 10, Train Loss: 6.3066, Val Loss: 7.1592\n",
      "Epoch 11, Train Loss: 6.1868, Val Loss: 7.1557\n",
      "Epoch 12, Train Loss: 6.0714, Val Loss: 7.1575\n",
      "Epoch 13, Train Loss: 5.9590, Val Loss: 7.1617\n",
      "Epoch 14, Train Loss: 5.8501, Val Loss: 7.1688\n",
      "Epoch 15, Train Loss: 5.7444, Val Loss: 7.1822\n",
      "Epoch 16, Train Loss: 5.6417, Val Loss: 7.1957\n",
      "Epoch 17, Train Loss: 5.5431, Val Loss: 7.2187\n",
      "Epoch 18, Train Loss: 5.4481, Val Loss: 7.2410\n",
      "Epoch 19, Train Loss: 5.3591, Val Loss: 7.2639\n",
      "Epoch 20, Train Loss: 5.2728, Val Loss: 7.2936\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T05:30:04.150078Z",
     "start_time": "2025-02-28T05:30:01.758124Z"
    }
   },
   "cell_type": "code",
   "source": "generate_summary(model, train_texts[0], vocab)",
   "id": "2e80a20793b4ae9b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zomato terry of a people are is the in in of in in and as year and was the new in the and been by people and the years and services and the uk and it is us is on after being and week in the new waiter in the the were the uk the is the the years than were from splits in in is the new ignition and in the us and have a be the a us in a new in the to the of the world the the new station is in for the the of in samaritans was on after the and week he the hospital waiter in the the in the uk the is was the years and in the one years the in were mers day of of to he the one years people were investigating he be been in a he have to be at the he the money and to the in and to and laden mayor in in of the health forces he was to her of is killed the incident in the are was a good happy bang of the from and was couple was he of a people and from was he woman overacted of to he the one years people were investigating he be been in a he have to be at the he the money and to the in and of the minister is a for the and the services in he the a says and the he couple is been to be the in the past of found down to to the us of with the world the the page and is the minister said said of laden and and the was been in accident with the and the the and police is the day death and in the scene and have a the the the incident in the man and the to the of the time the the new station is in to and minister to said of laden and and the was been in accident with the and the the and said the time of week the to in said to and laden and in and of the and and he was to his of man killed the incident in the he the the time in is been charged for to the hospital and the the public and and is of in in the killed by the are be a good conference in the time of the and the the than on the incident in he he the was a known and and for he guards are be a by by he incident was was to he of to not the to the incident were the servants have now are couple of the time to in a the time of the time the the the in day war of in on and in the of the he and the and hour and said was a a the car in with the and have been much to and the death and now and the life of a to of examiners and said to years and the uk to a as a incident enquirer of for the of year to the to to the media and after the incident in first of the world on in a the time of the world the the the in day war of in on the in the of the examiners and said to times and the uk to a as a incident enquirer of for the of year to the to to the media and after the first in were he the the the the to killed and to way of is and on of the the with the to to the the minute in is to the us of in the in made in investigated the the and the and the say were the money and couple was a first of the past to the have the he the office the the and and killed in the car at the crown for in day of the and to and found the years to to the in the police in week the the to the incident he couple is a by the and of the the and and the in to the house for couple heard the and a factor time and of is of the the and the and and he be a the the money and cup with couple is of to a to in the and and and not servants and'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
